\section{Conclus\~oes} \label{sec:conclusoes}

Nessa dissertação teve como objetivo mostrar a escassez de água que ocorreu em Curitiba, tornado possível uma tomada de decisão que foi uma adaptação do case de 12 etapas de \citeonline{de2013processo} que busca e visa o meio para ter a visão que não há interferência do meio, e se houver essa interferência listamos ela como variável exógena nos modelos do tipo ARX, ARIMAX e SARIMAX, nos modelos regressivos por mais que eles sejam bom de trabalhar não teve como incluir nesse momento.  Se o previsor busca as anomalias nos dados como foi feito aqui, olhamos para os dados de 2020 que foi a grande anomalia da SANEPAR, essas anomalia explicado os resultado no capítulo \ref{sec:result}. 


    \subsection{Limita\c c\~oes da pesquisa e propostas futuras}

As limitações desse trabalho resulta no tempo e os modelos de aprendizado de máquina, como visto no decorrer dessa dissertação, tem vários modelos que pode ser trabalhado em conjunto com a série temporal, por exemplo os modelos de redes neurais, LSTM, CNN, RNN... Entre outros modelos, não foi muito bem abordado aqui, pois são modelos mais complexo e exigiria uma gama maior de tempo, para esse momento apenas os modelos que foi trabalhado, a principio atendeu as questão de pesquisa que foi levantado.

Porém nos próximos passos para um trabalho futuro é abordar melhor esses modelos de previsão, tendo com muitos autores na literatura trabalhando com esses modelos, até competição de aprendizado de máquina com os modelos mais famosos, como o Light GBM em comparação com o XGboost, para previsão de curto prazo e para longo cada modelo tem sua relevância, LR como um modelo de no máximo 3 variáveis para dados com poucas viráveis ele é muito eficiente e ágil.

No trabalho que vai ser de sequência à esse como um complemento desse trabalho, tem como abordar a literatura inteira não apenas os últimos 6 anos, e também visa as outras parte que não foi abordado, como dissertação, tese e capítulos de livros, mesmo abordando um pequeno grupo de artigos ainda teve uma gama muito grande de artigos sobre o tema. 

A otimização matemática com alguns modelos sendo eles, floresta aleatória, XGboost, Ligth GBM, que poderia ser usado otimização para aumentar o gradiente e melhorar a precisão de aleatoriedade dos ramos das árvores. Métodos de otimização para melhorar o modelo foi \textbf{Grid Search, Randomized Search e Bayesian Optimization (Bayes Search)}  que vem do inglês, para o português seria \textbf{Pesquisa em grade, Pesquisa aleatória e Otimização Bayesiana} para o floresta aleatória o melhor método em hipótese séria o randomized, ele busca os galhos mais rápido da árvore, assim prevendo melhor o tempo, mas em tese todos eles em algum modelo não conseguiu reduzir os erros listado na seção \ref{subsec:metrica} ao invés de reduzir houve um aumento dos erros, fazendo que a previsão fosse ao longo do tempo ficando pior, como por exemplo no apêndice \ref{sec:ararxma24} que teve os melhores resultado se pegar os erros entre os modelos citados anteriormente, e em comparação aos modelos de otimização encontrado na literatura teve um aumento nos erros de 20 a 50 \%, e para uma previsão mais precisa é preciso que fique próximo de zero.

Nessa parte da otimização é relevante pesquisar ou ter mais aprofundamento nos hiperparâmetros, para ter um melhor aproveitamento dos modelos de árvore e dos gradientes. 